{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Importing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "from scipy import stats\n",
    "from google.colab import drive\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Visualization config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: defining variable and preparing csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/content/synthetic_stock_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: first visualization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verificar si el archivo existe en la ruta ---\n",
    "if os.path.exists(csv_path):\n",
    "    print(f\"Archivo encontrado en: {csv_path}\")\n",
    "    # --- Cargar el conjunto de datos ---\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(\"¡DataFrame cargado exitosamente!\")\n",
    "\n",
    "        # ==================================================\n",
    "        # 1.    Carga inicial del proyecto.\n",
    "        # ==================================================\n",
    "        print(\"\\n----- 1. Carga e Inspección Inicial -----\")\n",
    "\n",
    "        # Ver las primeras y últimas filas\n",
    "        print(\"\\nPrimeras 5 filas:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nÚltimas 5 filas:\")\n",
    "        print(df.tail())\n",
    "\n",
    "        # Obtener dimensiones\n",
    "        print(f\"\\nDimensiones del DataFrame (filas, columnas): {df.shape}\")\n",
    "\n",
    "        # Revisar tipos de datos y valores no nulos\n",
    "        print(\"\\nInformación del DataFrame (Tipos de datos y Nulos):\")\n",
    "        df.info()\n",
    "\n",
    "        # Obtener estadísticas descriptivas básicas para variables numéricas\n",
    "        print(\"\\nEstadísticas Descriptivas (Variables Numéricas):\")\n",
    "        print(df.describe().T) # Usar .T para transponer y facilitar la lectura\n",
    "\n",
    "        # Contar valores únicos por columna\n",
    "        print(\"\\nConteo de Valores Únicos por Columna:\")\n",
    "        print(df.nunique())\n",
    "\n",
    "        # ... (Aquí pegarías el resto del código del EDA: Limpieza, Univariado, Bivariado, etc.) ...\n",
    "        # El resto del código que te proporcioné anteriormente funcionará\n",
    "        # a partir de aquí, ya que la variable 'df' ahora contiene tus datos.\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo CSV: {e}\")\n",
    "        print(\"Asegúrate de que el archivo se subió correctamente y no está corrupto.\")\n",
    "\n",
    "else:\n",
    "    print(f\"¡ERROR! No se encontró el archivo en la ruta: {csv_path}\")\n",
    "    print(\"Por favor, asegúrate de haber subido el archivo 'synthetic_stock_data.csv' a tu sesión actual de Colab.\")\n",
    "    print(\"Puedes hacerlo usando el botón 'Subir archivo' en el panel de archivos de la izquierda.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: handling duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Manejo de Duplicados ---\n",
    "print(\"\\nNúmero de Filas Duplicadas:\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(duplicates)\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"\\nSe encontraron {duplicates} filas duplicadas. Eliminándolas.\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Nuevas dimensiones del DataFrame: {df.shape}\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron filas duplicadas.\")\n",
    "\n",
    "# --- Corrección de Tipos de Datos ---\n",
    "print(\"\\nVerificando y corrigiendo tipos de datos...\")\n",
    "# Convertir 'Date' a datetime si no lo está ya\n",
    "if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "    try:\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        print(\"'Date' convertida a tipo datetime.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir 'Date': {e}. Se mantendrá como objeto.\")\n",
    "else:\n",
    "    print(\"'Date' ya es de tipo datetime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 2. Análisis Univariado\n",
    "# ==================================================\n",
    "print(\"\\n----- 2. Análisis Univariado -----\")\n",
    "\n",
    "# Identificar columnas numéricas y categóricas (RE-IDENTIFICAR después de limpieza/corrección)\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "date_col = 'Date' # Definir explícitamente\n",
    "# Asegurarse de no incluir columnas no deseadas si su tipo cambió\n",
    "if 'Year' in numeric_cols: numeric_cols.remove('Year') # Si se crearon en una ejecución previa\n",
    "if 'Month' in numeric_cols: numeric_cols.remove('Month')\n",
    "if 'Day' in numeric_cols: numeric_cols.remove('Day')\n",
    "if 'DayOfWeek' in numeric_cols: numeric_cols.remove('DayOfWeek')\n",
    "\n",
    "print(f\"\\nColumnas Numéricas para Análisis Univariado: {numeric_cols}\")\n",
    "print(f\"Columnas Categóricas para Análisis Univariado: {categorical_cols}\")\n",
    "\n",
    "# --- Variables Numéricas ---\n",
    "print(\"\\nAnálisis de Variables Numéricas:\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n--- Análisis de '{col}' ---\")\n",
    "    if df[col].isnull().any():\n",
    "        print(f\"Advertencia: La columna '{col}' contiene valores NaN. Las estadísticas pueden verse afectadas.\")\n",
    "        # Considera df[col].dropna().skew() o .kurt() si quieres estadísticas sin NaNs\n",
    "        skewness = \"N/A (contiene NaN)\"\n",
    "        kurtosis = \"N/A (contiene NaN)\"\n",
    "    else:\n",
    "        skewness = f\"{df[col].skew():.2f}\"\n",
    "        kurtosis = f\"{df[col].kurt():.2f}\"\n",
    "\n",
    "    print(f\"Media: {df[col].mean():.2f}\")\n",
    "    print(f\"Mediana: {df[col].median():.2f}\")\n",
    "    print(f\"Desviación Estándar: {df[col].std():.2f}\")\n",
    "    print(f\"Mínimo: {df[col].min():.2f}\")\n",
    "    print(f\"Máximo: {df[col].max():.2f}\")\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    print(f\"Q1: {Q1:.2f}\")\n",
    "    print(f\"Q3: {Q3:.2f}\")\n",
    "    print(f\"IQR (Rango Intercuartílico): {IQR:.2f}\")\n",
    "    print(f\"Asimetría (Skewness): {skewness}\")\n",
    "    print(f\"Curtosis: {kurtosis}\")\n",
    "\n",
    "    # Visualización: Histograma y Boxplot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Usar dropna() para evitar errores en el plot si hay NaNs\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribución de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=df[col].dropna()) # Usar dropna() aquí también\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.ylabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Variables Categóricas ---\n",
    "print(\"\\nAnálisis de Variables Categóricas:\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n--- Análisis de '{col}' ---\")\n",
    "\n",
    "    # Frecuencias y Proporciones\n",
    "    print(\"Conteo de Valores:\")\n",
    "    value_counts = df[col].value_counts()\n",
    "    print(value_counts)\n",
    "    print(\"\\nProporción de Valores (%):\")\n",
    "    print(value_counts.div(value_counts.sum()).mul(100).round(2).astype(str) + '%')\n",
    "\n",
    "    # Visualización: Gráfico de Barras (si no hay demasiadas categorías)\n",
    "    num_unique = df[col].nunique()\n",
    "    print(f\"Número de categorías únicas: {num_unique}\")\n",
    "    if num_unique > 0 and num_unique < 30: # Umbral arbitrario y evitar error si columna está vacía\n",
    "        plt.figure(figsize=(10, max(5, num_unique * 0.3))) # Ajustar altura dinámicamente\n",
    "        sns.countplot(y=df[col], order = value_counts.index, palette='viridis')\n",
    "        plt.title(f'Frecuencia de Categorías en {col}')\n",
    "        plt.xlabel('Conteo')\n",
    "        plt.ylabel(col)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif num_unique >= 30:\n",
    "        print(f\"No se genera gráfico de barras para '{col}' debido a la alta cardinalidad ({num_unique} categorías).\")\n",
    "        print(\"Top 10 categorías:\")\n",
    "        print(value_counts.head(10))\n",
    "    else:\n",
    "         print(f\"La columna '{col}' no tiene valores o categorías únicas para graficar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 3. Análisis Bivariado\n",
    "# ==================================================\n",
    "print(\"\\n----- 3. Análisis Bivariado -----\")\n",
    "\n",
    "# --- Numérica vs. Numérica ---\n",
    "print(\"\\nAnálisis Numérica vs. Numérica:\")\n",
    "\n",
    "# Matriz de correlación y Mapa de calor\n",
    "print(\"\\nMatriz de Correlación:\")\n",
    "# Seleccionar solo columnas numéricas que existen en el df actual\n",
    "existing_numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
    "if existing_numeric_cols:\n",
    "    correlation_matrix = df[existing_numeric_cols].corr()\n",
    "    print(correlation_matrix)\n",
    "\n",
    "    print(\"\\nMapa de Calor de Correlación:\")\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, annot_kws={\"size\": 8})\n",
    "    plt.title('Mapa de Calor de Correlación entre Variables Numéricas')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se encontraron columnas numéricas para calcular la correlación.\")\n",
    "\n",
    "\n",
    "# Diagramas de dispersión (Seleccionar pares relevantes)\n",
    "print(\"\\nDiagramas de Dispersión (Ejemplos):\")\n",
    "# Verificar si las columnas existen antes de intentar plotear\n",
    "scatter_pairs = [('Open', 'Close'), ('Volume', 'Volatility'), ('PE_Ratio', 'Dividend_Yield')]\n",
    "plt.figure(figsize=(18, 6))\n",
    "plot_index = 1\n",
    "for x_col, y_col in scatter_pairs:\n",
    "    if x_col in df.columns and y_col in df.columns:\n",
    "        plt.subplot(1, len(scatter_pairs), plot_index)\n",
    "        sns.scatterplot(data=df, x=x_col, y=y_col, alpha=0.5)\n",
    "        plt.title(f'{x_col} vs {y_col}')\n",
    "        plot_index += 1\n",
    "    else:\n",
    "        print(f\"Advertencia: No se pueden plotear '{x_col}' vs '{y_col}' (una o ambas columnas faltan).\")\n",
    "if plot_index > 1: # Solo mostrar si se ploteó algo\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se pudieron generar diagramas de dispersión de ejemplo.\")\n",
    "\n",
    "\n",
    "# --- Categórica vs. Categórica ---\n",
    "print(\"\\nAnálisis Categórica vs. Categórica:\")\n",
    "\n",
    "# Ejemplo: Sector vs Trend\n",
    "if 'Sector' in categorical_cols and 'Trend' in categorical_cols:\n",
    "    print(\"\\nTabla de Contingencia: Sector vs Trend\")\n",
    "    try:\n",
    "        crosstab_st = pd.crosstab(df['Sector'], df['Trend'])\n",
    "        print(crosstab_st)\n",
    "\n",
    "        # Gráfico de barras agrupadas\n",
    "        crosstab_st.plot(kind='bar', figsize=(12, 7), rot=45)\n",
    "        plt.title('Distribución de Trend por Sector')\n",
    "        plt.xlabel('Sector')\n",
    "        plt.ylabel('Conteo')\n",
    "        plt.legend(title='Trend')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Prueba Chi-cuadrado (opcional)\n",
    "        try:\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(crosstab_st)\n",
    "            print(f\"\\nPrueba Chi-cuadrado (Sector vs Trend): Chi2={chi2:.2f}, p-value={p:.3f}\")\n",
    "            if p < 0.05:\n",
    "                print(\"Hay evidencia de una asociación significativa entre Sector y Trend (p < 0.05).\")\n",
    "            else:\n",
    "                print(\"No hay evidencia suficiente de una asociación significativa entre Sector y Trend (p >= 0.05).\")\n",
    "        except ValueError as ve:\n",
    "             print(f\"No se pudo realizar la prueba Chi-cuadrado (posiblemente por ceros en tabla): {ve}\")\n",
    "        except Exception as e:\n",
    "             print(f\"Error inesperado en la prueba Chi-cuadrado: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar la tabla de contingencia Sector vs Trend: {e}\")\n",
    "else:\n",
    "    print(\"No se encontraron las columnas 'Sector' y/o 'Trend' para el análisis Categórico-Categórico.\")\n",
    "\n",
    "\n",
    "# --- Numérica vs. Categórica ---\n",
    "print(\"\\nAnálisis Numérica vs. Categórica:\")\n",
    "\n",
    "# Ejemplo: Close vs Sector\n",
    "if 'Sector' in categorical_cols and 'Close' in existing_numeric_cols:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Ordenar por mediana para mejor visualización\n",
    "    order = df.groupby('Sector')['Close'].median().sort_values().index\n",
    "    sns.boxplot(data=df, x='Sector', y='Close', order=order, palette='viridis')\n",
    "    plt.title('Distribución de Close por Sector (Ordenado por Mediana)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nEstadísticas Descriptivas de 'Close' Agrupadas por 'Sector':\")\n",
    "    print(df.groupby('Sector')['Close'].describe())\n",
    "else:\n",
    "     print(\"No se encontraron las columnas 'Sector' y/o 'Close' para el análisis Numérico-Categórico.\")\n",
    "\n",
    "\n",
    "# Ejemplo: Sentiment_Score vs Trend\n",
    "if 'Trend' in categorical_cols and 'Sentiment_Score' in existing_numeric_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(data=df, x='Trend', y='Sentiment_Score', palette='muted', inner='quartile') # Mostrar cuartiles\n",
    "    plt.title('Distribución de Sentiment_Score por Trend')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nEstadísticas Descriptivas de 'Sentiment_Score' Agrupadas por 'Trend':\")\n",
    "    print(df.groupby('Trend')['Sentiment_Score'].describe())\n",
    "else:\n",
    "     print(\"No se encontraron las columnas 'Trend' y/o 'Sentiment_Score' para el análisis Numérico-Categórico.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Outliers handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 4. Identificación y Manejo de Outliers (Más a fondo)\n",
    "# ==================================================\n",
    "print(\"\\n----- 4. Identificación y Manejo de Outliers -----\")\n",
    "\n",
    "print(\"\\nIdentificación de Outliers usando el método IQR:\")\n",
    "# Revisaremos algunas columnas clave como ejemplo\n",
    "outlier_check_cols = ['Close', 'Volume', 'PE_Ratio', 'Volatility', 'Sentiment_Score', 'Market_Cap', 'Dividend_Yield']\n",
    "outlier_summary = {}\n",
    "\n",
    "for col in outlier_check_cols:\n",
    "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col]) and not df[col].isnull().all():\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Evitar errores si IQR es 0\n",
    "        if IQR > 0:\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            outlier_count = outliers.shape[0]\n",
    "            percentage = (outlier_count / df[col].notna().sum()) * 100 if df[col].notna().sum() > 0 else 0\n",
    "            outlier_summary[col] = {'count': outlier_count, 'percentage': percentage}\n",
    "\n",
    "            print(f\"\\nOutliers en '{col}': {outlier_count} ({percentage:.2f}%)\")\n",
    "            print(f\"  Límites (1.5*IQR): Inferior={lower_bound:.2f}, Superior={upper_bound:.2f}\")\n",
    "            if outlier_count > 0 and outlier_count < 15: # Mostrar algunos si no son demasiados\n",
    "                 print(\"  Algunos ejemplos de outliers:\")\n",
    "                 # Intentar mostrar Date si existe y es datetime\n",
    "                 cols_to_show = [col for col in [date_col,'Company', col] if col in outliers.columns]\n",
    "                 print(outliers[cols_to_show].head())\n",
    "            elif outlier_count >= 15:\n",
    "                 print(f\"  Se encontraron {outlier_count} outliers, no se muestran ejemplos por brevedad.\")\n",
    "                 print(f\"  Valor Mínimo Outlier (si existe < lower): {outliers[outliers[col] < lower_bound][col].min() if any(outliers[col] < lower_bound) else 'N/A'}\")\n",
    "                 print(f\"  Valor Máximo Outlier (si existe > upper): {outliers[outliers[col] > upper_bound][col].max() if any(outliers[col] > upper_bound) else 'N/A'}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n'{col}': IQR es 0, no se pueden calcular límites basados en IQR.\")\n",
    "            outlier_summary[col] = {'count': 0, 'percentage': 0.0}\n",
    "    elif col not in df.columns:\n",
    "         print(f\"\\nAdvertencia: La columna '{col}' no existe en el DataFrame.\")\n",
    "    elif not pd.api.types.is_numeric_dtype(df[col]):\n",
    "         print(f\"\\nAdvertencia: La columna '{col}' no es numérica.\")\n",
    "    else: # Es numérica pero todos son NaN\n",
    "         print(f\"\\nAdvertencia: La columna '{col}' solo contiene valores NaN.\")\n",
    "\n",
    "\n",
    "print(\"\\nResumen de Outliers (método 1.5*IQR):\")\n",
    "for col, data in outlier_summary.items():\n",
    "    print(f\"- {col}: {data['count']} outliers ({data['percentage']:.2f}%)\")\n",
    "\n",
    "\n",
    "print(\"\\nNota sobre el manejo de outliers:\")\n",
    "print(\"El tratamiento de outliers (eliminación, transformación, capping, uso de modelos robustos)\")\n",
    "print(\"depende críticamente del contexto del análisis, del dominio del problema y del objetivo final (ej: modelado).\")\n",
    "print(\"En este EDA inicial, solo los identificamos. Los boxplots del análisis univariado también ayudan a visualizarlos.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
