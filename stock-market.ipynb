{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Importing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "from scipy import stats\n",
    "from google.colab import drive\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Visualization config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: defining variable and preparing csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/content/synthetic_stock_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: first visualization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verificar si el archivo existe en la ruta ---\n",
    "if os.path.exists(csv_path):\n",
    "    print(f\"Archivo encontrado en: {csv_path}\")\n",
    "    # --- Cargar el conjunto de datos ---\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(\"¡DataFrame cargado exitosamente!\")\n",
    "\n",
    "        # ==================================================\n",
    "        # 1.    Carga inicial del proyecto.\n",
    "        # ==================================================\n",
    "        print(\"\\n----- 1. Carga e Inspección Inicial -----\")\n",
    "\n",
    "        # Ver las primeras y últimas filas\n",
    "        print(\"\\nPrimeras 5 filas:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nÚltimas 5 filas:\")\n",
    "        print(df.tail())\n",
    "\n",
    "        # Obtener dimensiones\n",
    "        print(f\"\\nDimensiones del DataFrame (filas, columnas): {df.shape}\")\n",
    "\n",
    "        # Revisar tipos de datos y valores no nulos\n",
    "        print(\"\\nInformación del DataFrame (Tipos de datos y Nulos):\")\n",
    "        df.info()\n",
    "\n",
    "        # Obtener estadísticas descriptivas básicas para variables numéricas\n",
    "        print(\"\\nEstadísticas Descriptivas (Variables Numéricas):\")\n",
    "        print(df.describe().T) # Usar .T para transponer y facilitar la lectura\n",
    "\n",
    "        # Contar valores únicos por columna\n",
    "        print(\"\\nConteo de Valores Únicos por Columna:\")\n",
    "        print(df.nunique())\n",
    "\n",
    "        # ... (Aquí pegarías el resto del código del EDA: Limpieza, Univariado, Bivariado, etc.) ...\n",
    "        # El resto del código que te proporcioné anteriormente funcionará\n",
    "        # a partir de aquí, ya que la variable 'df' ahora contiene tus datos.\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo CSV: {e}\")\n",
    "        print(\"Asegúrate de que el archivo se subió correctamente y no está corrupto.\")\n",
    "\n",
    "else:\n",
    "    print(f\"¡ERROR! No se encontró el archivo en la ruta: {csv_path}\")\n",
    "    print(\"Por favor, asegúrate de haber subido el archivo 'synthetic_stock_data.csv' a tu sesión actual de Colab.\")\n",
    "    print(\"Puedes hacerlo usando el botón 'Subir archivo' en el panel de archivos de la izquierda.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: handling duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Manejo de Duplicados ---\n",
    "print(\"\\nNúmero de Filas Duplicadas:\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(duplicates)\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"\\nSe encontraron {duplicates} filas duplicadas. Eliminándolas.\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Nuevas dimensiones del DataFrame: {df.shape}\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron filas duplicadas.\")\n",
    "\n",
    "# --- Corrección de Tipos de Datos ---\n",
    "print(\"\\nVerificando y corrigiendo tipos de datos...\")\n",
    "# Convertir 'Date' a datetime si no lo está ya\n",
    "if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "    try:\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        print(\"'Date' convertida a tipo datetime.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir 'Date': {e}. Se mantendrá como objeto.\")\n",
    "else:\n",
    "    print(\"'Date' ya es de tipo datetime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 2. Análisis Univariado\n",
    "# ==================================================\n",
    "print(\"\\n----- 2. Análisis Univariado -----\")\n",
    "\n",
    "# Identificar columnas numéricas y categóricas (RE-IDENTIFICAR después de limpieza/corrección)\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "date_col = 'Date' # Definir explícitamente\n",
    "# Asegurarse de no incluir columnas no deseadas si su tipo cambió\n",
    "if 'Year' in numeric_cols: numeric_cols.remove('Year') # Si se crearon en una ejecución previa\n",
    "if 'Month' in numeric_cols: numeric_cols.remove('Month')\n",
    "if 'Day' in numeric_cols: numeric_cols.remove('Day')\n",
    "if 'DayOfWeek' in numeric_cols: numeric_cols.remove('DayOfWeek')\n",
    "\n",
    "print(f\"\\nColumnas Numéricas para Análisis Univariado: {numeric_cols}\")\n",
    "print(f\"Columnas Categóricas para Análisis Univariado: {categorical_cols}\")\n",
    "\n",
    "# --- Variables Numéricas ---\n",
    "print(\"\\nAnálisis de Variables Numéricas:\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n--- Análisis de '{col}' ---\")\n",
    "    if df[col].isnull().any():\n",
    "        print(f\"Advertencia: La columna '{col}' contiene valores NaN. Las estadísticas pueden verse afectadas.\")\n",
    "        # Considera df[col].dropna().skew() o .kurt() si quieres estadísticas sin NaNs\n",
    "        skewness = \"N/A (contiene NaN)\"\n",
    "        kurtosis = \"N/A (contiene NaN)\"\n",
    "    else:\n",
    "        skewness = f\"{df[col].skew():.2f}\"\n",
    "        kurtosis = f\"{df[col].kurt():.2f}\"\n",
    "\n",
    "    print(f\"Media: {df[col].mean():.2f}\")\n",
    "    print(f\"Mediana: {df[col].median():.2f}\")\n",
    "    print(f\"Desviación Estándar: {df[col].std():.2f}\")\n",
    "    print(f\"Mínimo: {df[col].min():.2f}\")\n",
    "    print(f\"Máximo: {df[col].max():.2f}\")\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    print(f\"Q1: {Q1:.2f}\")\n",
    "    print(f\"Q3: {Q3:.2f}\")\n",
    "    print(f\"IQR (Rango Intercuartílico): {IQR:.2f}\")\n",
    "    print(f\"Asimetría (Skewness): {skewness}\")\n",
    "    print(f\"Curtosis: {kurtosis}\")\n",
    "\n",
    "    # Visualización: Histograma y Boxplot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Usar dropna() para evitar errores en el plot si hay NaNs\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribución de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=df[col].dropna()) # Usar dropna() aquí también\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.ylabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Variables Categóricas ---\n",
    "print(\"\\nAnálisis de Variables Categóricas:\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n--- Análisis de '{col}' ---\")\n",
    "\n",
    "    # Frecuencias y Proporciones\n",
    "    print(\"Conteo de Valores:\")\n",
    "    value_counts = df[col].value_counts()\n",
    "    print(value_counts)\n",
    "    print(\"\\nProporción de Valores (%):\")\n",
    "    print(value_counts.div(value_counts.sum()).mul(100).round(2).astype(str) + '%')\n",
    "\n",
    "    # Visualización: Gráfico de Barras (si no hay demasiadas categorías)\n",
    "    num_unique = df[col].nunique()\n",
    "    print(f\"Número de categorías únicas: {num_unique}\")\n",
    "    if num_unique > 0 and num_unique < 30: # Umbral arbitrario y evitar error si columna está vacía\n",
    "        plt.figure(figsize=(10, max(5, num_unique * 0.3))) # Ajustar altura dinámicamente\n",
    "        sns.countplot(y=df[col], order = value_counts.index, palette='viridis')\n",
    "        plt.title(f'Frecuencia de Categorías en {col}')\n",
    "        plt.xlabel('Conteo')\n",
    "        plt.ylabel(col)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif num_unique >= 30:\n",
    "        print(f\"No se genera gráfico de barras para '{col}' debido a la alta cardinalidad ({num_unique} categorías).\")\n",
    "        print(\"Top 10 categorías:\")\n",
    "        print(value_counts.head(10))\n",
    "    else:\n",
    "         print(f\"La columna '{col}' no tiene valores o categorías únicas para graficar.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
